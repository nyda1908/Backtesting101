{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import the necessary packages\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!wget https://huggingface.co/datasets/JEFFREY-VERDIERE/Creditcard/resolve/main/creditcard.csv -O creditcard.csv\nimport pandas as pd\ndf = pd.read_csv(\"creditcard.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for col in df.columns:\n    print(col)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Shape of the dataset:\", df.shape)\nprint(\"\\nSummary statistics:\")\nprint(df.describe())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Null values in each column:\")\nprint(df.isna().sum())             #shows how many nulls each column has\n\ndf = df.dropna()                   #removes any rows that contain at least one null value\n\nprint(\"\\nAfter dropping nulls, null values in each column:\")\nprint(df.isna().sum())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.hist(figsize=(20, 20))  #figsize adjustable\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#1 indicates fraud, 0 indicates valid transaction \n\n#fraud cases\nfraud_cases = df[df['Class'] == 1]\nprint(\"Number of Fraud Cases:\", len(fraud_cases))\n\n#valid cases\nvalid_cases = df[df['Class'] == 0]\nprint(\"Number of Valid Cases:\", len(valid_cases))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Correlation matrix EXAMPLE\ncorrmat=df.corr()\nfig=plt.figure(figsize=(36,25))\n\nsns.heatmap(corrmat, vmax = .8, square = True,annot=True,cmap=\"coolwarm\",linewidth=2)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#get all the columns from the dataFrame \nall_columns = df.columns.tolist()\n\n#filter \ncolumns = [col for col in all_columns if col != 'Class']\n\n#store the target column separately\ntarget = 'Class'\n\nX = df[columns]     # All columns except 'Class'\nY = df[target]      # Only the 'Class' column\n\nprint(\"Shape of X (features):\", X.shape)\nprint(\"Shape of Y (target):\", Y.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"X_train shape:\", X_train.shape)\nprint(\"X_test shape:\", X_test.shape)\nprint(\"Y_train shape:\", Y_train.shape)\nprint(\"Y_test shape:\", Y_test.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nX_train_sc=sc.fit_transform(X_train)  # convert all data into float data type\nX_test_sc=sc.transform(X_test)\nX_test_sc.dtype","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report, accuracy_score","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#train decision tree classifier\nfrom sklearn.tree import DecisionTreeClassifier\n\ndt_model = DecisionTreeClassifier(random_state=42)\ndt_model.fit(X_train, Y_train)\n\n#predict on test data\ny_pred = dt_model.predict(X_test)\n\n#accuracy score\naccuracy = accuracy_score(Y_test, y_pred)\nprint(f\"Accuracy Score: {accuracy:.10f}\")  ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#train with standard scalar\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\n#fit and transform training data, transform test data\nX_train_sc = scaler.fit_transform(X_train)\nX_test_sc = scaler.transform(X_test)\n\ndt_model_scaled = DecisionTreeClassifier(random_state=42)\ndt_model_scaled.fit(X_train_sc, Y_train)\n\n#predict and evaluate\ny_pred_scaled = dt_model_scaled.predict(X_test_sc)\naccuracy_scaled = accuracy_score(Y_test, y_pred_scaled)\n\nprint(f\"Scaled Accuracy Score: {accuracy_scaled:.10f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Random forest classifier, fit on Xtrain achieved by splitting\nfrom sklearn.ensemble import RandomForestClassifier\nrf_clf=RandomForestClassifier(n_estimators=20,criterion=\"entropy\",random_state=5)\nrf_clf.fit(X_train,Y_train)\ny_pred_rf=rf_clf.predict(X_test)\naccuracy_score(Y_test,y_pred_rf)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train with Standard Scalar, (instead of X_train, fit on X_train_sc and X_test_sc, achieve by scaling)\nrf_clf_sc=RandomForestClassifier(n_estimators=20,criterion=\"entropy\",random_state=5)\nrf_clf_sc.fit(X_train_sc,Y_train)\ny_pred_rf_sc=rf_clf_sc.predict(X_test_sc)\naccuracy_score(Y_test,y_pred_rf_sc)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Adaboost classifier\nfrom sklearn.ensemble import AdaBoostClassifier\nabd_clf=AdaBoostClassifier(DecisionTreeClassifier(criterion=\"entropy\",random_state=20),\n                                                  n_estimators=200,\n                                                   learning_rate=0.1,\n                                                   algorithm=\"SAMME\",\n                                                   random_state=1, )\n\nabd_clf.fit(X_train,Y_train)\ny_pred_abd=abd_clf.predict(X_test)\naccuracy_score(Y_test,y_pred_abd)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train with Standard Scalar, fit on X_train_sc achieved by scaling\nabd_clf_sc=AdaBoostClassifier(DecisionTreeClassifier(criterion=\"entropy\",random_state=20),\n                             n_estimators=200,\n                             learning_rate=0.1,\n                             algorithm=\"SAMME\",\n                             random_state=1,)\nabd_clf_sc.fit(X_train_sc,Y_train)\ny_pred_abd_sc=abd_clf_sc.predict(X_test_sc)\naccuracy_score(Y_test,y_pred_abd_sc)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n#train the model\nxgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\nxgb_model.fit(X_train, Y_train)\n\n#predict\ny_pred_xgb = xgb_model.predict(X_test)\n\n#accuracy score\naccuracy_xgb = accuracy_score(Y_test, y_pred_xgb)\nprint(f\"XGBoost Accuracy (no scaling): {accuracy_xgb:.10f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xgb_model_scaled = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\nxgb_model_scaled.fit(X_train_sc, Y_train)\n\n#predict\ny_pred_xgb_scaled = xgb_model_scaled.predict(X_test_sc)\n\n#accuracy\naccuracy_xgb_scaled = accuracy_score(Y_test, y_pred_xgb_scaled)\nprint(f\"XGBoost Accuracy (with scaling): {accuracy_xgb_scaled:.10f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#create the confusion matrix\ncm = confusion_matrix(Y_test, y_pred_xgb)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#plotting the confusion matrix\nplt.figure(figsize=(6, 4))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', linewidths=1, linecolor='black')\n\n#labels and title\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.title('Confusion Matrix')\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(Y_test, y_pred_xgb, target_names=[\"Valid\", \"Fraud\"]))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}